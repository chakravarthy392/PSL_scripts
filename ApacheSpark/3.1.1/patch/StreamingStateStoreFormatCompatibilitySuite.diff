diff --git a/sql/core/src/test/scala/org/apache/spark/sql/streaming/StreamingStateStoreFormatCompatibilitySuite.scala b/sql/core/src/test/scala/org/apache/spark/sql/streaming/StreamingStateStoreFormatCompatibilitySuite.scala
index 1032d6c5b6..25e3622844 100644
--- a/sql/core/src/test/scala/org/apache/spark/sql/streaming/StreamingStateStoreFormatCompatibilitySuite.scala
+++ b/sql/core/src/test/scala/org/apache/spark/sql/streaming/StreamingStateStoreFormatCompatibilitySuite.scala
@@ -18,6 +18,7 @@
 package org.apache.spark.sql.streaming
 
 import java.io.File
+import java.nio.ByteOrder
 
 import scala.annotation.tailrec
 
@@ -51,6 +52,9 @@ class StreamingStateStoreFormatCompatibilitySuite extends StreamTest {
   }
 
   test("common functions") {
+    // TODO: provide checkpoint data generated on a big-endian system.
+    assume(ByteOrder.nativeOrder().equals(ByteOrder.LITTLE_ENDIAN))
+
     val inputData = MemoryStream[Int]
     val aggregated =
       inputData.toDF().toDF("value")
@@ -123,6 +127,9 @@ class StreamingStateStoreFormatCompatibilitySuite extends StreamTest {
   }
 
   test("statistical functions") {
+    // TODO: provide checkpoint data generated on a big-endian system.
+    assume(ByteOrder.nativeOrder().equals(ByteOrder.LITTLE_ENDIAN))
+
     val inputData = MemoryStream[Long]
     val aggregated =
       inputData.toDF().toDF("value")
@@ -186,6 +193,9 @@ class StreamingStateStoreFormatCompatibilitySuite extends StreamTest {
   }
 
   test("deduplicate with all columns") {
+    // TODO: provide checkpoint data generated on a big-endian system.
+    assume(ByteOrder.nativeOrder().equals(ByteOrder.LITTLE_ENDIAN))
+
     val inputData = MemoryStream[Long]
     val result = inputData.toDF().toDF("value")
       .selectExpr(
@@ -220,6 +230,9 @@ class StreamingStateStoreFormatCompatibilitySuite extends StreamTest {
   }
 
   test("SPARK-28067 changed the sum decimal unsafe row format") {
+    // TODO: provide checkpoint data generated on a big-endian system.
+    assume(ByteOrder.nativeOrder().equals(ByteOrder.LITTLE_ENDIAN))
+
     val inputData = MemoryStream[Int]
     val aggregated =
       inputData.toDF().toDF("value")
