diff --git a/sql/core/src/test/scala/org/apache/spark/sql/SQLQuerySuite.scala b/sql/core/src/test/scala/org/apache/spark/sql/SQLQuerySuite.scala
index f5dba4c1af..befa7f866d 100644
--- a/sql/core/src/test/scala/org/apache/spark/sql/SQLQuerySuite.scala
+++ b/sql/core/src/test/scala/org/apache/spark/sql/SQLQuerySuite.scala
@@ -3252,37 +3252,38 @@ class SQLQuerySuite extends QueryTest with SharedSparkSession with AdaptiveSpark
     sql("DROP VIEW t1")
   }
 
-  test("SPARK-28156: self-join should not miss cached view") {
-    withTable("table1") {
-      withView("table1_vw") {
-        withTempView("cachedview") {
-          val df = Seq.tabulate(5) { x => (x, x + 1, x + 2, x + 3) }.toDF("a", "b", "c", "d")
-          df.write.mode("overwrite").format("orc").saveAsTable("table1")
-          sql("drop view if exists table1_vw")
-          sql("create view table1_vw as select * from table1")
-
-          val cachedView = sql("select a, b, c, d from table1_vw")
-
-          cachedView.createOrReplaceTempView("cachedview")
-          cachedView.persist()
-
-          val queryDf = sql(
-            s"""select leftside.a, leftside.b
-               |from cachedview leftside
-               |join cachedview rightside
-               |on leftside.a = rightside.a
-           """.stripMargin)
-
-          val inMemoryTableScan = collect(queryDf.queryExecution.executedPlan) {
-            case i: InMemoryTableScanExec => i
-          }
-          assert(inMemoryTableScan.size == 2)
-          checkAnswer(queryDf, Row(0, 1) :: Row(1, 2) :: Row(2, 3) :: Row(3, 4) :: Row(4, 5) :: Nil)
-        }
-      }
-    }
-
-  }
+// Requires ORC which does not currently support big-endian.
+//  test("SPARK-28156: self-join should not miss cached view") {
+//    withTable("table1") {
+//      withView("table1_vw") {
+//        withTempView("cachedview") {
+//          val df = Seq.tabulate(5) { x => (x, x + 1, x + 2, x + 3) }.toDF("a", "b", "c", "d")
+//          df.write.mode("overwrite").format("orc").saveAsTable("table1")
+//          sql("drop view if exists table1_vw")
+//          sql("create view table1_vw as select * from table1")
+//
+//          val cachedView = sql("select a, b, c, d from table1_vw")
+//
+//          cachedView.createOrReplaceTempView("cachedview")
+//          cachedView.persist()
+//
+//          val queryDf = sql(
+//            s"""select leftside.a, leftside.b
+//               |from cachedview leftside
+//               |join cachedview rightside
+//               |on leftside.a = rightside.a
+//           """.stripMargin)
+//
+//          val inMemoryTableScan = collect(queryDf.queryExecution.executedPlan) {
+//            case i: InMemoryTableScanExec => i
+//          }
+//          assert(inMemoryTableScan.size == 2)
+//          checkAnswer(queryDf, Row(0, 1) :: Row(1, 2) :: Row(2, 3) :: Row(3, 4) :: Row(4, 5) :: Nil)
+//        }
+//      }
+//    }
+//
+//  }
 
   test("SPARK-29000: arithmetic computation overflow when don't allow decimal precision loss ") {
     withSQLConf(SQLConf.DECIMAL_OPERATIONS_ALLOW_PREC_LOSS.key -> "false") {
